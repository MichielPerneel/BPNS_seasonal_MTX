{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of Metabolic Pathways\n",
    "In this notebook, I want to analyze all KEGG pathways found in the metatranscriptome. We'll combine them with taxonomic information to analyze contributions of different taxonomic groups to the specific pathway.\n",
    "First, we'll need to gather the data needed to do this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KOs and their associated pathways that have been included in the WGCNA analysis\n",
    "KO_info = pd.read_csv(\"../../data/analysis/WGCNA/ko_pathway_info.csv\")\n",
    "\n",
    "# The transcript functional annotation data\n",
    "annotation = pd.read_csv('../../data/annotation/functional_eggnog/functional_annotation.emapper.annotations', sep = '\\t', engine = 'pyarrow')\n",
    "\n",
    "## Fix transcript names in the first column so that they equal the transcript identifiers in the count files\n",
    "## This is necessary because TransDecoder adds .p2 or .p1 to the sequence identifiers\n",
    "annotation.iloc[:, 0] = annotation.iloc[:, 0].str.split(\".\", expand=True).drop(columns=1)\n",
    "\n",
    "# The transcript counts\n",
    "counts = pd.read_csv('../../data/kallisto/tpm.csv', sep=',', index_col=0, engine='pyarrow')\n",
    "\n",
    "# The EukProt taxonomic annotation data\n",
    "eukprot_annotation = pd.read_table(f'../../data/annotation/taxonomy_eukprot/eukprot_DB.firsthit.90plus_alnscore.m8', header=None)\n",
    "## Fix transcript names in the first column so that they equal the transcript identifiers in the count files\n",
    "eukprot_annotation.iloc[:, 0] = eukprot_annotation.iloc[:, 0].str.split(\".\", expand=True).drop(columns=1)\n",
    "\n",
    "## In the second column, split of the EukProt ID off\n",
    "eukprot_ID = eukprot_annotation.iloc[:, 1].str.split(\"_\", expand=True)[0]\n",
    "eukprot_annotation.iloc[:, 1] = eukprot_ID\n",
    "eukprot_annotation.columns = ['query_id', 'target_id', 'p_ident', 'alnlen', 'mismatch', 'gapopen', 'qstart', 'qend', 'tstart', 'tend', 'evalue', 'bits']\n",
    "\n",
    "## Add taxonomic information\n",
    "eukprot_taxonomy = pd.read_table('../../data/annotation/taxonomy_eukprot/EukProt_included_data_sets.v03.2021_11_22.txt')\n",
    "\n",
    "## Drop the columns that are not needed\n",
    "eukprot_taxonomy.drop(columns=['Previous_Names', 'Replaces_EukProt_ID', 'Data_Source_URL', 'Data_Source_Name', 'Paper_DOI', 'Actions_Prior_to_Use',\n",
    "       'Data_Source_Type', 'Notes', 'Columns_Modified_Since_Previous_Version', 'Merged_Strains',\n",
    "       'Alternative_Strain_Names', '18S_Sequence_GenBank_ID', '18S_Sequence',\n",
    "       '18S_Sequence_Source', '18S_Sequence_Other_Strain_GenBank_ID',\n",
    "       '18S_Sequence_Other_Strain_Name', '18S_and_Taxonomy_Notes'], inplace=True)\n",
    "\n",
    "## Swap the _ to a space in the Name_to_Use column\n",
    "eukprot_taxonomy['Name_to_Use'] = eukprot_taxonomy['Name_to_Use'].str.replace('_', ' ')\n",
    "\n",
    "## Merge the annotation and taxonomy files\n",
    "eukprot_annotation = eukprot_annotation.merge(eukprot_taxonomy, left_on='target_id', right_on='EukProt_ID', how='left')\n",
    "\n",
    "## Drop the columns that are not needed\n",
    "eukprot_annotation.drop(columns=['target_id', 'gapopen', 'qstart', 'qend', 'tstart', 'tend', 'evalue', 'bits'], inplace=True)\n",
    "\n",
    "# The shallow EukProt taxonomic annotation data\n",
    "eukprot_annotation_60 = pd.read_table(f'../../data/annotation/taxonomy_eukprot/eukprot_DB.firsthit.60plus_alnscore.m8', header=None)\n",
    "## Fix transcript names in the first column so that they equal the transcript identifiers in the count files\n",
    "eukprot_annotation_60.iloc[:, 0] = eukprot_annotation_60.iloc[:, 0].str.split(\".\", expand=True).drop(columns=1)\n",
    "\n",
    "## In the second column, split of the EukProt ID off\n",
    "eukprot_ID = eukprot_annotation_60.iloc[:, 1].str.split(\"_\", expand=True)[0]\n",
    "eukprot_annotation_60.iloc[:, 1] = eukprot_ID\n",
    "eukprot_annotation_60.columns = ['query_id', 'target_id', 'p_ident', 'alnlen', 'mismatch', 'gapopen', 'qstart', 'qend', 'tstart', 'tend', 'evalue', 'bits']\n",
    "\n",
    "## Add taxonomic information\n",
    "eukprot_taxonomy = pd.read_table('../../data/annotation/taxonomy_eukprot/EukProt_included_data_sets.v03.2021_11_22.txt')\n",
    "\n",
    "## Drop the columns that are not needed\n",
    "eukprot_taxonomy.drop(columns=['Previous_Names', 'Replaces_EukProt_ID', 'Data_Source_URL', 'Data_Source_Name', 'Paper_DOI', 'Actions_Prior_to_Use',\n",
    "       'Data_Source_Type', 'Notes', 'Columns_Modified_Since_Previous_Version', 'Merged_Strains',\n",
    "       'Alternative_Strain_Names', '18S_Sequence_GenBank_ID', '18S_Sequence',\n",
    "       '18S_Sequence_Source', '18S_Sequence_Other_Strain_GenBank_ID',\n",
    "       '18S_Sequence_Other_Strain_Name', '18S_and_Taxonomy_Notes'], inplace=True)\n",
    "\n",
    "## Swap the _ to a space in the Name_to_Use column\n",
    "eukprot_taxonomy['Name_to_Use'] = eukprot_taxonomy['Name_to_Use'].str.replace('_', ' ')\n",
    "\n",
    "## Merge the annotation and taxonomy files\n",
    "eukprot_annotation_60 = eukprot_annotation_60.merge(eukprot_taxonomy, left_on='target_id', right_on='EukProt_ID', how='left')\n",
    "\n",
    "## Drop the columns that are not needed\n",
    "eukprot_annotation_60.drop(columns=['target_id', 'gapopen', 'qstart', 'qend', 'tstart', 'tend', 'evalue', 'bits'], inplace=True)\n",
    "\n",
    "## load metadata\n",
    "meta = pd.read_csv('../../samples.csv', sep=';', index_col=0)\n",
    "## Set the order of the months in the metadata\n",
    "month_order = [\"July_2020\", \"August_2020\", \"September_2020\", \"November_2020\", \n",
    "                \"December_2020\", \"January_2021\", \"February_2021\", \"April_2021\", \n",
    "                \"May_2021\", \"June_2021\", \"July_2021\"]\n",
    "\n",
    "# Fetch all pathway descriptors\n",
    "pathways = KO_info['Pathway'].str.extractall(r\"'(map\\d+)'\")[0].unique()\n",
    "\n",
    "# Read the pathway info from the csv file\n",
    "pathway_info = pd.read_csv('../../data/analysis/WGCNA/pathway_info.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now from these datasets I want to create two dataframes:\n",
    "1. A dataframe containing the pathways, samples, and their total expression at that moment\n",
    "2. A dataframe containing the pathways, the taxonomic annotation (Taxogroup2_UniEuk, Genus_UniEuk, Name_to_Use), the sampling date, station, and total expression at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathway_expression(pathways, pathway_info, KO_info, annotation, counts, meta, result_path='../../data/analysis/WGCNA/pathway_TPM_sum.csv'):\n",
    "    results = []\n",
    "\n",
    "    for pathway in tqdm(pathways, desc=\"Analyzing Pathways\"):\n",
    "        # Filtering KO_info for rows where the Pathway column contains the current pathway\n",
    "        ko_values = KO_info[KO_info['Pathway'].str.contains(pathway)]['KEGG_ID'].tolist()\n",
    "        \n",
    "        # Filtering annotation DataFrame for rows where KEGG_ko column contains any value in ko_values\n",
    "        transcript_names = annotation[annotation['KEGG_ko'].str.contains('|'.join(ko_values))]['#query'].tolist()\n",
    "\n",
    "        # Extract Pathway_Name and Pathway_Class from pathway_info DataFrame\n",
    "        pathway_name = pathway_info[pathway_info['pathway_id'] == pathway]['name'].values[0] if pathway in pathway_info['pathway_id'].values else 'N/A'\n",
    "        pathway_class = pathway_info[pathway_info['pathway_id'] == pathway]['class'].values[0] if pathway in pathway_info['pathway_id'].values else 'N/A'\n",
    "\n",
    "        for sample in meta.index:\n",
    "            # Get the total expression of transcripts involved in this pathway in this sample\n",
    "            tpm = counts[sample].loc[transcript_names].sum()\n",
    "        \n",
    "            results.append({\n",
    "                'Pathway_ID': pathway,\n",
    "                'Pathway_Name': pathway_name,\n",
    "                'Pathway_Class': pathway_class,\n",
    "                'Sample': sample,\n",
    "                'TPM': tpm\n",
    "                })\n",
    "    \n",
    "    # Create DataFrame and save as CSV\n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.to_csv(result_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing Pathways: 100%|██████████| 464/464 [12:04<00:00,  1.56s/it] \n"
     ]
    }
   ],
   "source": [
    "# Run the function\n",
    "pathway_expression(pathways, pathway_info, KO_info, annotation, counts, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathway_taxonomic_expression(pathways, pathway_info, KO_info, annotation, eukprot_annotation, counts, meta, result_path='../../data/analysis/WGCNA/pathway_tax_TPM_sum.csv'):\n",
    "    # Merging annotation with eukprot_annotation to get the Taxogroup2_UniEuk information\n",
    "    annotation = annotation.merge(eukprot_annotation[['query_id', 'Taxogroup2_UniEuk']], left_on='#query', right_on='query_id', how='left')\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for pathway in tqdm(pathways, desc=\"Analyzing Pathways\"):\n",
    "        ko_values = KO_info[KO_info['Pathway'].str.contains(pathway)]['KEGG_ID'].tolist()\n",
    "        transcript_names = annotation[annotation['KEGG_ko'].str.contains('|'.join(ko_values))]\n",
    "\n",
    "        pathway_name = pathway_info[pathway_info['pathway_id'] == pathway]['name'].values[0] if pathway in pathway_info['pathway_id'].values else 'N/A'\n",
    "        pathway_class = pathway_info[pathway_info['pathway_id'] == pathway]['class'].values[0] if pathway in pathway_info['pathway_id'].values else 'N/A'\n",
    "\n",
    "        for sample in meta.index:\n",
    "            tpm_data = counts[sample].loc[transcript_names['#query']]\n",
    "            transcript_names_copy = transcript_names.copy()  \n",
    "            transcript_names_copy['TPM'] = tpm_data.values\n",
    "            tpm_sum = transcript_names_copy.groupby('Taxogroup2_UniEuk')['TPM'].sum().reset_index()\n",
    "\n",
    "            for _, row in tpm_sum.iterrows():\n",
    "                results.append({\n",
    "                    'Pathway_ID': pathway,\n",
    "                    'Pathway_Name': pathway_name,\n",
    "                    'Pathway_Class': pathway_class,\n",
    "                    'Sample': sample,\n",
    "                    'Taxogroup2_UniEuk': row['Taxogroup2_UniEuk'],\n",
    "                    'TPM': row['TPM']\n",
    "                })\n",
    "\n",
    "    # Create DataFrame and save as CSV\n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.to_csv(result_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing Pathways: 100%|██████████| 464/464 [12:24<00:00,  1.60s/it] \n"
     ]
    }
   ],
   "source": [
    "# Run the function\n",
    "pathway_taxonomic_expression(pathways, pathway_info, KO_info, annotation, eukprot_annotation, counts, meta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
